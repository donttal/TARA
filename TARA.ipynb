{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHyzQEz4ZZYH"
      },
      "source": [
        "# Global modification of hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QdmEpz1DZYt8",
        "outputId": "1b291a47-a3d1-4345-8ab2-c62fd015e48f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bert_mix_template_soft_fewshot_10_bankSize_16_dataset_emotion.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 234
        }
      ],
      "source": [
        "# 模型设定NoCollapse是带SVD的Bert版本\n",
        "Model_lst = [\"NoCollapse\",\"Bert\",\"Bert_large\",\"roberta-base\",\"roberta-large\",\"ALBERT\",\"roberta-large-mnli\"]\n",
        "PLM_TYPE = Model_lst[1]\n",
        "\n",
        "# training_type_lst决定了loss的设置\n",
        "training_type_lst = ['man','mix','original','low_level','medium_level','high_level','bank','multiple','collapse','new_collapse']\n",
        "training_type = training_type_lst[1]\n",
        "\n",
        "# prompt模板的选择\n",
        "template_lst = ['man','soft','mix','ptuning','ptr']\n",
        "template_type = template_lst[1]\n",
        "\n",
        "# few-shot\n",
        "num_examples_per_label_ = 10\n",
        "\n",
        "# Data construction, full data, standard few-shot, construction of few-shot based on data distribution of dataset\n",
        "data_con_lst = ['full_data','fewshot','DA']\n",
        "data_con = data_con_lst[1]\n",
        "\n",
        "# few-shot or zero-shot\n",
        "few_shot_train = True\n",
        "# few_shot_train = False\n",
        "\n",
        "# lr 常规是model=1e-4/2e-5 template=1e-3/1e-2\n",
        "model_lr = 1e-4\n",
        "template_lr= 1e-3\n",
        "\n",
        "# 数据集选择\n",
        "dataset_lst = [\"go_emotions\",\"emotion\"]\n",
        "dataset_ = dataset_lst[-1]\n",
        "\n",
        "# 超参数\n",
        "epoch_num = 5\n",
        "bank_size = 16\n",
        "batch_size_ = 8\n",
        "\n",
        "use_cuda = True\n",
        "# use_cuda = False\n",
        "\n",
        "if data_con == \"full_data\":\n",
        "  model_save_pth = PLM_TYPE+\"_\"+str(training_type)+\"_template_\"+template_type+\"_\"+data_con+\"_\"+\"_bankSize_\"+str(bank_size)+\"_dataset_\"+dataset_+\".pth\"\n",
        "else:\n",
        "  model_save_pth = PLM_TYPE+\"_\"+str(training_type)+\"_template_\"+template_type+\"_\"+data_con+\"_\"+str(num_examples_per_label_)+\"_bankSize_\"+str(bank_size)+\"_dataset_\"+dataset_+\".pth\"\n",
        "\n",
        "model_save_pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j3WxS4OgxYl"
      },
      "source": [
        "# Development Dependent Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIBTlwMaCbVj",
        "outputId": "2067cbb6-21e9-45c7-e60e-b9e45f9c73e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "9jVRgcTSfVUS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "framework_root = \"/content/drive/MyDrive/Colab/OpenPromptV2/\"\n",
        "os.chdir(framework_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfVD4RbJfdD4",
        "outputId": "bd67c904-04c1-4e32-8e8f-8086a1469fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.21.2)\n",
            "Requirement already satisfied: sentencepiece==0.1.96 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.1.96)\n",
            "Requirement already satisfied: tqdm>=4.62.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.64.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.5.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.1.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.3.5.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.4.0)\n",
            "Requirement already satisfied: rouge==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge==1.0.0->-r requirements.txt (line 10)) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (0.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers>=4.10.0->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.10.0->-r requirements.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (3.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (2022.7.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (0.70.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (1.3.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (0.18.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->-r requirements.txt (line 1)) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->-r requirements.txt (line 1)) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (4.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.10.0->-r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r requirements.txt (line 9)) (2022.2.1)\n",
            "requirements:\n",
            "['transformers>=4.10.0', 'sentencepiece==0.1.96', '# scikit-learn>=0.24.2', 'tqdm>=4.62.2', 'tensorboardX', 'nltk', 'yacs', 'dill', 'datasets', 'rouge==1.0.0', 'pyarrow', 'scipy']\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing openprompt.egg-info/PKG-INFO\n",
            "writing dependency_links to openprompt.egg-info/dependency_links.txt\n",
            "writing requirements to openprompt.egg-info/requires.txt\n",
            "writing top-level names to openprompt.egg-info/top_level.txt\n",
            "reading manifest file 'openprompt.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'openprompt.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying openprompt/prompt_base.py -> build/lib/openprompt\n",
            "copying openprompt/pipeline_base.py -> build/lib/openprompt\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/openprompt\n",
            "copying build/lib/openprompt/config.py -> build/bdist.linux-x86_64/egg/openprompt\n",
            "copying build/lib/openprompt/default_config.py -> build/bdist.linux-x86_64/egg/openprompt\n",
            "copying build/lib/openprompt/protoverb_trainer.py -> build/bdist.linux-x86_64/egg/openprompt\n",
            "copying build/lib/openprompt/trainer.py -> build/bdist.linux-x86_64/egg/openprompt\n",
            "copying build/lib/openprompt/lm_bff_trainer.py -> build/bdist.linux-x86_64/egg/openprompt\n",
            "copying build/lib/openprompt/__init__.py -> build/bdist.linux-x86_64/egg/openprompt\n",
            "creating build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/one2one_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/generation_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/soft_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/manual_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/ptr_prompts.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/ptuning_prompts.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/knowledgeable_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/prefix_tuning_template.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/automatic_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/mixed_template.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/prompt_generator.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/manual_template.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/prototypical_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "copying build/lib/openprompt/prompts/soft_template.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
            "creating build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "copying build/lib/openprompt/plms/utils.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "copying build/lib/openprompt/plms/seq2seq.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "copying build/lib/openprompt/plms/mlm.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "copying build/lib/openprompt/plms/lm.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "copying build/lib/openprompt/plms/RobertaForMaskedLMV2.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "copying build/lib/openprompt/plms/BertForNoCollapseV2.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "copying build/lib/openprompt/plms/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "copying build/lib/openprompt/plms/BertForNoCollapse.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "copying build/lib/openprompt/plms/BertForMaskedLMV2.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
            "creating build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/relation_classification_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/lama_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/utils.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/fewglue_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/huggingface_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/text_classification_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/conditional_generation_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/data_processor.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/data_sampler.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/typing_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "copying build/lib/openprompt/data_utils/nli_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
            "creating build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/sentiment.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/entity_typing.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/processor.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/generation.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/summarization.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/closed_QA.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/paraphrase.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/relation.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/coreference.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/nli.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/topic_classification.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "copying build/lib/openprompt/data_utils/ZH/reading_comprehensation.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
            "creating build/bdist.linux-x86_64/egg/openprompt/utils\n",
            "copying build/lib/openprompt/utils/cuda.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
            "copying build/lib/openprompt/utils/utils.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
            "copying build/lib/openprompt/utils/metrics.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
            "copying build/lib/openprompt/utils/crossfit_metrics.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
            "copying build/lib/openprompt/utils/calibrate.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
            "copying build/lib/openprompt/utils/reproduciblity.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
            "copying build/lib/openprompt/utils/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
            "copying build/lib/openprompt/utils/logging.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
            "copying build/lib/openprompt/prompt_base.py -> build/bdist.linux-x86_64/egg/openprompt\n",
            "copying build/lib/openprompt/pipeline_base.py -> build/bdist.linux-x86_64/egg/openprompt\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/config.py to config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/default_config.py to default_config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/protoverb_trainer.py to protoverb_trainer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/trainer.py to trainer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/lm_bff_trainer.py to lm_bff_trainer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/one2one_verbalizer.py to one2one_verbalizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/generation_verbalizer.py to generation_verbalizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/soft_verbalizer.py to soft_verbalizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/manual_verbalizer.py to manual_verbalizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/ptr_prompts.py to ptr_prompts.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/ptuning_prompts.py to ptuning_prompts.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/knowledgeable_verbalizer.py to knowledgeable_verbalizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/prefix_tuning_template.py to prefix_tuning_template.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/automatic_verbalizer.py to automatic_verbalizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/mixed_template.py to mixed_template.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/prompt_generator.py to prompt_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/manual_template.py to manual_template.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/prototypical_verbalizer.py to prototypical_verbalizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/soft_template.py to soft_template.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/seq2seq.py to seq2seq.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/mlm.py to mlm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/lm.py to lm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/RobertaForMaskedLMV2.py to RobertaForMaskedLMV2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/BertForNoCollapseV2.py to BertForNoCollapseV2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/BertForNoCollapse.py to BertForNoCollapse.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/BertForMaskedLMV2.py to BertForMaskedLMV2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/relation_classification_dataset.py to relation_classification_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/lama_dataset.py to lama_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/fewglue_dataset.py to fewglue_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/huggingface_dataset.py to huggingface_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/text_classification_dataset.py to text_classification_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/conditional_generation_dataset.py to conditional_generation_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/data_processor.py to data_processor.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/data_sampler.py to data_sampler.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/typing_dataset.py to typing_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/nli_dataset.py to nli_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/sentiment.py to sentiment.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/entity_typing.py to entity_typing.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/processor.py to processor.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/generation.py to generation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/summarization.py to summarization.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/closed_QA.py to closed_QA.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/paraphrase.py to paraphrase.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/relation.py to relation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/coreference.py to coreference.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/nli.py to nli.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/topic_classification.py to topic_classification.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/reading_comprehensation.py to reading_comprehensation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/cuda.py to cuda.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/metrics.py to metrics.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/crossfit_metrics.py to crossfit_metrics.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/calibrate.py to calibrate.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/reproduciblity.py to reproduciblity.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/logging.py to logging.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompt_base.py to prompt_base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/openprompt/pipeline_base.py to pipeline_base.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying openprompt.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying openprompt.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying openprompt.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying openprompt.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying openprompt.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "openprompt.prompts.__pycache__.prototypical_verbalizer.cpython-37: module MAY be using inspect.stack\n",
            "creating 'dist/openprompt-1.0.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing openprompt-1.0.0-py3.7.egg\n",
            "removing '/usr/local/lib/python3.7/dist-packages/openprompt-1.0.0-py3.7.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.7/dist-packages/openprompt-1.0.0-py3.7.egg\n",
            "Extracting openprompt-1.0.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "openprompt 1.0.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/openprompt-1.0.0-py3.7.egg\n",
            "Processing dependencies for openprompt==1.0.0\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyarrow==6.0.1\n",
            "Best match: pyarrow 6.0.1\n",
            "Adding pyarrow 6.0.1 to easy-install.pth file\n",
            "Installing plasma_store script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for rouge==1.0.0\n",
            "Best match: rouge 1.0.0\n",
            "Adding rouge 1.0.0 to easy-install.pth file\n",
            "Installing rouge script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for datasets==2.4.0\n",
            "Best match: datasets 2.4.0\n",
            "Adding datasets 2.4.0 to easy-install.pth file\n",
            "Installing datasets-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for dill==0.3.5.1\n",
            "Best match: dill 0.3.5.1\n",
            "Adding dill 0.3.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for yacs==0.1.8\n",
            "Best match: yacs 0.1.8\n",
            "Adding yacs 0.1.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for nltk==3.7\n",
            "Best match: nltk 3.7\n",
            "Adding nltk 3.7 to easy-install.pth file\n",
            "Installing nltk script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboardX==2.5.1\n",
            "Best match: tensorboardX 2.5.1\n",
            "Adding tensorboardX 2.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for sentencepiece==0.1.96\n",
            "Best match: sentencepiece 0.1.96\n",
            "Adding sentencepiece 0.1.96 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for transformers==4.21.2\n",
            "Best match: transformers 4.21.2\n",
            "Adding transformers 4.21.2 to easy-install.pth file\n",
            "Installing transformers-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for fsspec==2022.7.1\n",
            "Best match: fsspec 2022.7.1\n",
            "Adding fsspec 2022.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for huggingface-hub==0.9.1\n",
            "Best match: huggingface-hub 0.9.1\n",
            "Adding huggingface-hub 0.9.1 to easy-install.pth file\n",
            "Installing huggingface-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==4.12.0\n",
            "Best match: importlib-metadata 4.12.0\n",
            "Adding importlib-metadata 4.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pandas==1.3.5\n",
            "Best match: pandas 1.3.5\n",
            "Adding pandas 1.3.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for responses==0.18.0\n",
            "Best match: responses 0.18.0\n",
            "Adding responses 0.18.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for packaging==21.3\n",
            "Best match: packaging 21.3\n",
            "Adding packaging 21.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for xxhash==3.0.0\n",
            "Best match: xxhash 3.0.0\n",
            "Adding xxhash 3.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for aiohttp==3.8.1\n",
            "Best match: aiohttp 3.8.1\n",
            "Adding aiohttp 3.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for multiprocess==0.70.13\n",
            "Best match: multiprocess 0.70.13\n",
            "Adding multiprocess 0.70.13 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for regex==2022.6.2\n",
            "Best match: regex 2022.6.2\n",
            "Adding regex 2022.6.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for joblib==1.1.0\n",
            "Best match: joblib 1.1.0\n",
            "Adding joblib 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for click==7.1.2\n",
            "Best match: click 7.1.2\n",
            "Adding click 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tokenizers==0.12.1\n",
            "Best match: tokenizers 0.12.1\n",
            "Adding tokenizers 0.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for filelock==3.8.0\n",
            "Best match: filelock 3.8.0\n",
            "Adding filelock 3.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.1.1\n",
            "Best match: typing-extensions 4.1.1\n",
            "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.8.1\n",
            "Best match: zipp 3.8.1\n",
            "Adding zipp 3.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pytz==2022.2.1\n",
            "Best match: pytz 2022.2.1\n",
            "Adding pytz 2022.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.25.11\n",
            "Best match: urllib3 1.25.11\n",
            "Adding urllib3 1.25.11 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for attrs==22.1.0\n",
            "Best match: attrs 22.1.0\n",
            "Adding attrs 22.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for frozenlist==1.3.1\n",
            "Best match: frozenlist 1.3.1\n",
            "Adding frozenlist 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for aiosignal==1.2.0\n",
            "Best match: aiosignal 1.2.0\n",
            "Adding aiosignal 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for async-timeout==4.0.2\n",
            "Best match: async-timeout 4.0.2\n",
            "Adding async-timeout 4.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for asynctest==0.13.0\n",
            "Best match: asynctest 0.13.0\n",
            "Adding asynctest 0.13.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for yarl==1.8.1\n",
            "Best match: yarl 1.8.1\n",
            "Adding yarl 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for charset-normalizer==2.1.0\n",
            "Best match: charset-normalizer 2.1.0\n",
            "Adding charset-normalizer 2.1.0 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for multidict==6.0.2\n",
            "Best match: multidict 6.0.2\n",
            "Adding multidict 6.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.6.15\n",
            "Best match: certifi 2022.6.15\n",
            "Adding certifi 2022.6.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for openprompt==1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r  requirements.txt\n",
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a8QRfUnQD6l",
        "outputId": "eff8cf55-fc69-4350-dd1d-2300d27b59ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-metric-learning in /usr/local/lib/python3.7/dist-packages (1.5.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.21.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (0.13.1+cu113)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.1.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-metric-learning) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-metric-learning) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        " !pip install pytorch-metric-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaDFysCpg-fm"
      },
      "source": [
        "# Dataset (go_emotions/emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "hcv96uk4CUTy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from openprompt.utils.reproduciblity import set_seed\n",
        "import re\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    set_seed(seed)\n",
        "\n",
        "set_seeds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "x91HHJQoCUTz"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e6004a06cbfb4c548248ac401c5a3bac",
            "20db683d57d94a549d5245e2c20ab086",
            "9cb2c5eec2ef4edc9009b3ffd022483d",
            "c179a157bb904d5db8afcc8884e7273e",
            "31068be0a724498db2163128dc7c080b",
            "355d83a428b240d6b437c974c9354aef",
            "1cdf63658bb74662a5c615af3c43ffc7",
            "cb0d1853ccfe456f98412b8bf99cf035",
            "980384950f714e629a89e66c55bb811a",
            "9ac99ed05961491eae0cb54c13777ac7",
            "f03f80c49853499eb66d96dc2afe8843"
          ]
        },
        "id": "IhmPKRMOcPeT",
        "outputId": "be999ee2-9084-46ac-9d82-a51f2cce0872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default\n",
            "WARNING:datasets.builder:Reusing dataset emotion (/root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6004a06cbfb4c548248ac401c5a3bac"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "if dataset_ == \"go_emotions\":\n",
        "  emotions = load_dataset(\"go_emotions\",\"simplified\")\n",
        "\n",
        "  df_train = emotions['train'].to_pandas()\n",
        "  df_dev = emotions['validation'].to_pandas()\n",
        "  df_test = emotions['test'].to_pandas()\n",
        "\n",
        "  # Adjusting the order to determine if the hierarchy can be retained\n",
        "  # Since the dataset and the paper are in a different tag order, reset\n",
        "  labels_ = ['amusement','excitement','joy','love','desire','optimism','caring','pride','admiration','gratitude','relief','approval','realization','surprise','curiosity','confusion', 'fear', 'nervousness', 'remorse','embarrassment','disappointment', 'sadness','grief','disgust','anger','annoyance','disapproval','neutral']\n",
        "  labels_cols = [\"admiration\",\"amusement\",\"anger\",\"annoyance\",\"approval\",\"caring\",\"confusion\",\"curiosity\",\"desire\",\"disappointment\",\"disapproval\",\"disgust\",\"embarrassment\",\"excitement\",\"fear\", \"gratitude\",\"grief\",\"joy\",\"love\",\"nervousness\",\"optimism\",\"pride\",\"realization\",\"relief\",\"remorse\",\"sadness\",\"surprise\",\"neutral\"]\n",
        "\n",
        "  change_dict = {}\n",
        "  for idx, item in enumerate(labels_cols):\n",
        "    change_dict[idx] = labels_.index(item)\n",
        "  \n",
        "  print(change_dict)\n",
        "  print(labels_)\n",
        "  print(len(labels_))\n",
        "\n",
        "  df_train[\"labels_num\"] = list(map(len, df_train[\"labels\"].values.tolist())) \n",
        "  df_train = df_train.drop(df_train[df_train[\"labels_num\"]!=1].index)\n",
        "  print(df_train[\"labels\"].values.tolist()[0])\n",
        "  df_train[\"label\"] = list(map(lambda a: change_dict[a.tolist()[0]], df_train[\"labels\"].values.tolist()))\n",
        "  df_train[\"idx\"] = df_train.index\n",
        "\n",
        "  df_dev[\"labels_num\"] = list(map(len, df_dev[\"labels\"].values.tolist())) \n",
        "  df_dev = df_dev.drop(df_dev[df_dev[\"labels_num\"]!=1].index)\n",
        "  df_dev[\"label\"] = list(map(lambda a: change_dict[a.tolist()[0]], df_dev[\"labels\"].values.tolist()))\n",
        "  df_dev[\"idx\"] = df_dev.index\n",
        "\n",
        "  df_test[\"labels_num\"] = list(map(len, df_test[\"labels\"].values.tolist())) \n",
        "  df_test = df_test.drop(df_test[df_test[\"labels_num\"]!=1].index)\n",
        "  df_test[\"label\"] = list(map(lambda a: change_dict[a.tolist()[0]], df_test[\"labels\"].values.tolist()))\n",
        "  df_test[\"idx\"] = df_test.index\n",
        "\n",
        "elif dataset_ == \"emotion\":\n",
        "  emo = load_dataset(dataset_)\n",
        "  \n",
        "  label_cols = [\"sadness\",\"joy\",\"love\",\"anger\",\"fear\",\"surprise\"]\n",
        "  labels_ = label_cols\n",
        "\n",
        "  df_train = emo['train'].to_pandas()\n",
        "  df_train[\"idx\"] = df_train.index\n",
        "\n",
        "  df_dev = emo['validation'].to_pandas()\n",
        "  df_dev[\"idx\"] = df_dev.index\n",
        "\n",
        "  df_test = emo['test'].to_pandas()\n",
        "  df_test[\"idx\"] = df_test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "jB8OcNdjCUT1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "raw_dataset = {\"train\": df_train, \"validation\": df_dev, \"test\": df_test}\n",
        "# print(raw_dataset)\n",
        "# print(type(raw_dataset[\"train\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data distribution"
      ],
      "metadata": {
        "id": "_ycfH7QK-2sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_train))\n",
        "\n",
        "max_num = 0\n",
        "max_labels = 0\n",
        "\n",
        "\n",
        "for i in range(len(label_cols)):\n",
        "  cur_num = len(df_train[df_train[\"label\"]==i])\n",
        "  if max_num < cur_num:\n",
        "    max_num = cur_num\n",
        "\n",
        "labels_dict = {}\n",
        "for i in range(len(label_cols)):\n",
        "  labels_dict[i]=len(df_train[df_train[\"label\"]==i])/max_num\n",
        "\n",
        "labels_dict"
      ],
      "metadata": {
        "id": "XNT88EUFKH5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246a8bfc-ef4b-40ae-d3b0-4183745f188d"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.8701976874300634,\n",
              " 1: 1.0,\n",
              " 2: 0.24319283849309958,\n",
              " 3: 0.40264826557254757,\n",
              " 4: 0.3612458038045505,\n",
              " 5: 0.10667661320402835}"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Thqm7PehqFW"
      },
      "source": [
        "# openprompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "WLzpArYRq7iI"
      },
      "outputs": [],
      "source": [
        "from openprompt.data_utils import InputExample\n",
        "\n",
        "dataset = {}\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    dataset[split] = []\n",
        "    # iter dataframe type\n",
        "    # print(type(raw_dataset[split]))\n",
        "    for _, data in raw_dataset[split].iterrows():\n",
        "        # print(dataset_)\n",
        "        input_example = InputExample(\n",
        "            text_a=data[\"text\"], label=data[\"label\"], guid=data[\"idx\"])\n",
        "        # print(input_example)\n",
        "        dataset[split].append(input_example)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(5):\n",
        "#     print(dataset['train'][i])"
      ],
      "metadata": {
        "id": "ZZwA1lkBiA1Q"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6-iCjUehw11"
      },
      "source": [
        "## load PLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAuzj77VCUT2",
        "outputId": "9a61d642-73ed-47bd-c510-c25bc0b28c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# You can load the plm related things provided by openprompt simply by calling:\n",
        "from openprompt.plms import load_plm\n",
        "\n",
        "if PLM_TYPE == \"NoCollapse\":\n",
        "  plm, tokenizer, model_config, WrapperClass = load_plm(\"BertForNoCollapse\", \"bert-base-cased\")\n",
        "elif PLM_TYPE == \"Bert\":\n",
        "  plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-cased\")\n",
        "elif PLM_TYPE == \"Bert_large\":\n",
        "  plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-large-cased\")\n",
        "elif PLM_TYPE == \"roberta-base\":\n",
        "  plm, tokenizer, model_config, WrapperClass = load_plm(\"roberta\", \"roberta-base\")\n",
        "elif PLM_TYPE == \"roberta-large\":\n",
        "  plm, tokenizer, model_config, WrapperClass = load_plm(\"roberta\", \"roberta-large\")\n",
        "elif PLM_TYPE == \"roberta-large-mnli\":\n",
        "  plm, tokenizer, model_config, WrapperClass = load_plm(\"roberta\", \"roberta-large-mnli\")\n",
        "elif PLM_TYPE == \"ALBERT\":\n",
        "  plm, tokenizer, model_config, WrapperClass = load_plm(\"albert\", \"albert-base-v2\")\n",
        "else:\n",
        "  print(\"Other models are not yet supported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT7PS1BcN431"
      },
      "source": [
        "##  ManualTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "xyIWLjerNDm0"
      },
      "outputs": [],
      "source": [
        "# Constructing Template\n",
        "# A template can be constructed from the yaml config, but it can also be constructed by directly passing arguments.\n",
        "from openprompt.prompts import ManualTemplate, SoftTemplate, MixedTemplate, PtuningTemplate, PTRTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "uoVZ_tnRNAod"
      },
      "outputs": [],
      "source": [
        "if template_type == \"man\":\n",
        "  # GoEmotions\n",
        "  # man\n",
        "  # template_text = '{\"placeholder\":\"text_a\"} Is was {\"mask\"}.'\n",
        "  # template_text = '{\"placeholder\":\"text_a\"} I am {\"mask\"}.'\n",
        "  template_text = '{\"placeholder\":\"text_a\"} The emotional aspect of this text is {\"mask\"}.'\n",
        "  mytemplate = ManualTemplate(tokenizer=tokenizer, text=template_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifGGDVCAya-W"
      },
      "source": [
        "## SoftTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "VGWM3eUONKg6"
      },
      "outputs": [],
      "source": [
        "if template_type == \"soft\":\n",
        "  # Soft\n",
        "  # id 可以将相同文本保持一样的soft \n",
        "  # when self.text is '{\"soft\": None} {\"soft\": \"the\", \"soft_id\": 1} {\"soft\": None} {\"soft\": \"it\", \"soft_id\": 3} {\"soft_id\": 1} {\"soft\": \"was\"} {\"mask\"}', output is [1, 2, 3, 4, 2, 5, 0]\n",
        "  # template_text = '{\"placeholder\":\"text_a\"} {\"soft\": \"It was\"} {\"mask\"}.'\n",
        "  # template_text = '{\"placeholder\":\"text_a\"} {\"soft\": None, \"duplicate\": 10, \"same\": True} {\"mask\"}.'\n",
        "\n",
        "  template_text = '{\"placeholder\":\"text_a\"} {\"soft\": \"The emotional aspect of this text is\"} {\"mask\"}.'\n",
        "\n",
        "  # template_text = '{\"placeholder\":\"text_a\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"mask\"}.'\n",
        "  # template_text = '{\"placeholder\": \"text_a\"} {\"placeholder\": \"text_b\"} {\"mask\"} .'\n",
        "\n",
        "  mytemplate = SoftTemplate(model=plm, tokenizer=tokenizer, text=template_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irfGFCZ6yfRX"
      },
      "source": [
        "## MixedTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "BSibNyz4NamK"
      },
      "outputs": [],
      "source": [
        "if template_type == \"mix\":\n",
        "  # 目前次好的temple\n",
        "  # template_text = '{\"placeholder\":\"text_a\"} {\"soft\": \"It was\"} {\"mask\"}.'\n",
        "  # 目前最好的temple\n",
        "  template_text = '{\"placeholder\":\"text_a\"} {\"soft\": \"The\"} emotional {\"soft\": \"aspect of this text is\"} {\"mask\"}.'\n",
        "\n",
        "  # template_text = '{\"soft\"} Emotion: {\"soft\"} {\"placeholder\":\"text_a\"} {\"soft\": \"The\"} emotional {\"soft\": \"aspect of this text is\"} {\"mask\"}.'\n",
        "  # template_text = '{\"placeholder\":\"text_a\"} {\"soft\": \"The\"} emotional {\"soft\": \"aspect of this text is\"} {\"mask\"} {\"soft\"}.'\n",
        "  # template_text = '{\"placeholder\":\"text_a\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"mask\"} .'\n",
        "\n",
        "  mytemplate = MixedTemplate(model=plm, tokenizer=tokenizer, text=template_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeMuWgtnyjGm"
      },
      "source": [
        "## PtuningTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "rS7xPTMfCUT2"
      },
      "outputs": [],
      "source": [
        "if template_type == \"ptuning\":\n",
        "  # ptuning\n",
        "  # 经过预训练导出的embedding高度离散化 不能够学习到soft之间的关系 ptuning使用的是ptuning 用mlp或者lstm模型初始化embedding\n",
        "\n",
        "\n",
        "  # # 实验主要适用模板\n",
        "  # template_text = '{\"soft\"} Emotion {\"soft\"} {\"mask\"} {\"soft\"} {\"placeholder\": \"text_a\"}'\n",
        "\n",
        "  # # 目前次好的temple 06/28 macro_f1 = 0.056622359610616534\n",
        "  # template_text = '{\"placeholder\":\"text_a\"} {\"soft\": \"It was\"} {\"mask\"}.'\n",
        "\n",
        "  # 目前最好的temple 06/28 macro_f1 = 0.06245602902611468\n",
        "  template_text = '{\"placeholder\":\"text_a\"} {\"soft\": \"The\"} emotional {\"soft\": \"aspect of this text is\"} {\"mask\"}.'\n",
        "\n",
        "  # template_text = '{\"placeholder\": \"text_a\"} {\"soft\"} emotion {\"soft\"} {\"soft\"} {\"mask\"} {\"soft\"}.'\n",
        "  # template_text = '{\"soft\"} Emotion: {\"soft\"} {\"mask\"} {\"soft\"} {\"placeholder\": \"text_a\"}'\n",
        "  # template_text = '{\"placeholder\": \"text_a\"} {\"soft\"} emotional {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"mask\"} {\"soft\"}.'\n",
        "  # template_text = '{\"placeholder\": \"text_a\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"soft\"} {\"mask\"}'\n",
        "\n",
        "  mytemplate = PtuningTemplate(model=plm, tokenizer=tokenizer, text=template_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PTR Template"
      ],
      "metadata": {
        "id": "huJ6_sQPpxt8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "arq_0SNMFAmZ"
      },
      "outputs": [],
      "source": [
        "if template_type == \"ptr\":\n",
        "  template_text = '{\"placeholder\":\"text_a\"} {\"soft\": \"The\"} emotional {\"soft\": \"aspect of this text is\"} {\"mask\"}.'\n",
        "  mytemplate = PTRTemplate(model=plm, tokenizer=tokenizer, text=template_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA8C761vNxUC",
        "outputId": "c4d46c82-5036-4c70-8130-932d9ec81ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"guid\": 0,\n",
            "  \"label\": 0,\n",
            "  \"meta\": {},\n",
            "  \"text_a\": \"i didnt feel humiliated\",\n",
            "  \"text_b\": \"\",\n",
            "  \"tgt_text\": null\n",
            "}\n",
            "\n",
            "[[{'text': 'i didnt feel humiliated', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': '', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}, {'text': '.', 'loss_ids': 0, 'shortenable_ids': 0}], {'guid': 0, 'label': 0}]\n"
          ]
        }
      ],
      "source": [
        "# To better understand how does the template wrap the example, we visualize one instance.\n",
        "print(dataset['train'][0])\n",
        "wrapped_example = mytemplate.wrap_one_example(dataset['train'][0]) \n",
        "print(wrapped_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNFNFFEbh_a_"
      },
      "source": [
        "# Few-shot & dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "wneFgDeSCUT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e73fb81-588d-437e-f863-a2fc6cb5f0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        }
      ],
      "source": [
        "from openprompt.data_utils.data_sampler import FewShotSampler\n",
        "\n",
        "\n",
        "support_sampler = FewShotSampler(num_examples_per_label=num_examples_per_label_,also_sample_dev=False)\n",
        "dataset['support'] = support_sampler(dataset['train'], seed=42)\n",
        "print(len(dataset['support']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if data_con == \"DA\":\n",
        "  datasetDA_dict = {}\n",
        "  labels_dict_ = {}\n",
        "  for k, v in labels_dict.items():\n",
        "    labels_dict_[k] = int(max(v*num_examples_per_label_,1))\n",
        "  print(labels_dict_)\n",
        "\n",
        "  for item in dataset['support']:\n",
        "    cur_label = int(item.label)\n",
        "    if cur_label not in datasetDA_dict.keys():\n",
        "      datasetDA_dict[cur_label] = []\n",
        "    \n",
        "    if len(datasetDA_dict[cur_label]) == labels_dict[cur_label]:\n",
        "      continue\n",
        "\n",
        "    datasetDA_dict[cur_label].append(item)\n",
        "\n",
        "  dataset[\"DA\"] = []\n",
        "  for i in datasetDA_dict.values():\n",
        "    for j in i:\n",
        "      dataset[\"DA\"].append(j)\n",
        "  print(len(dataset[\"DA\"]))"
      ],
      "metadata": {
        "id": "Nb6QeEjnqEDG"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "a7fpZpklCUT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70efdbd-59a9-4fe6-c634-ce4ed0cf41a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing: 60it [00:00, 1206.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"input_ids\": [[101, 178, 1821, 2296, 1897, 17278, 103, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 178, 1631, 2504, 1374, 1552, 103, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 178, 1631, 1177, 26121, 1219, 1343, 1551, 178, 1108, 7851, 4006, 1250, 103, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 178, 1221, 13280, 1543, 170, 1992, 2239, 1149, 1104, 1122, 1133, 178, 1631, 2385, 6764, 1115, 178, 1169, 2797, 103, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 178, 1631, 178, 4819, 1140, 1176, 178, 1138, 1309, 1518, 5687, 2256, 1176, 1115, 1133, 178, 1169, 1204, 1831, 1702, 1120, 1117, 3685, 5961, 103, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 178, 2059, 1132, 19967, 1113, 1241, 2192, 1133, 1195, 1138, 1562, 1159, 1105, 1254, 1115, 9366, 1389, 1930, 5115, 1277, 1167, 6970, 1106, 1123, 1190, 1131, 1674, 1106, 1140, 103, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 178, 1631, 1176, 178, 182, 1113, 1103, 4172, 1322, 1104, 170, 5973, 2035, 103, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 178, 1567, 1103, 189, 11613, 11734, 1105, 178, 1821, 2140, 1177, 1215, 1106, 1122, 1115, 178, 2140, 1631, 1107, 3121, 3080, 14459, 1919, 1796, 103, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"inputs_embeds\": null, \"attention_mask\": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"token_type_ids\": null, \"label\": [1, 3, 0, 5, 3, 2, 3, 4], \"decoder_input_ids\": null, \"decoder_inputs_embeds\": null, \"soft_token_ids\": null, \"past_key_values\": null, \"loss_ids\": [[-100, 0, 0, 0, 0, 0, 1, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [-100, 0, 0, 0, 0, 0, 1, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"guid\": [12372, 2530, 88, 15433, 5619, 2381, 342, 4831], \"tgt_text\": null, \"encoded_tgt_text\": null, \"input_ids_len\": null}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing: 2000it [00:01, 1167.12it/s]\n"
          ]
        }
      ],
      "source": [
        "from openprompt import PromptDataLoader\n",
        "\n",
        "if data_con == 'fewshot':\n",
        "  train_dataloader = PromptDataLoader(\n",
        "          dataset = dataset['support'],\n",
        "          template = mytemplate, \n",
        "          tokenizer = tokenizer, \n",
        "          tokenizer_wrapper_class=WrapperClass,\n",
        "          max_seq_length=128,\n",
        "          decoder_max_length=3,\n",
        "          batch_size=batch_size_ ,\n",
        "          shuffle=True,\n",
        "          teacher_forcing=False, \n",
        "          predict_eos_token=False,\n",
        "          truncate_method=\"tail\"\n",
        "  )\n",
        "elif data_con == 'full_data':\n",
        "  train_dataloader = PromptDataLoader(\n",
        "        dataset = dataset['train'],\n",
        "        template = mytemplate, \n",
        "        tokenizer = tokenizer, \n",
        "        tokenizer_wrapper_class=WrapperClass,\n",
        "        max_seq_length=128,\n",
        "        decoder_max_length=3,\n",
        "        batch_size=batch_size_ ,\n",
        "        shuffle=True,\n",
        "        teacher_forcing=False, \n",
        "        predict_eos_token=False,\n",
        "        truncate_method=\"tail\"\n",
        ")\n",
        "elif data_con == 'DA':\n",
        "  train_dataloader = PromptDataLoader(\n",
        "        dataset = dataset[\"DA\"],\n",
        "        template = mytemplate, \n",
        "        tokenizer = tokenizer, \n",
        "        tokenizer_wrapper_class=WrapperClass,\n",
        "        max_seq_length=128,\n",
        "        decoder_max_length=3,\n",
        "        batch_size=batch_size_ ,\n",
        "        shuffle=True,\n",
        "        teacher_forcing=False, \n",
        "        predict_eos_token=False,\n",
        "        truncate_method=\"tail\"\n",
        ")\n",
        "print(next(iter(train_dataloader)))\n",
        "\n",
        "# Evaluate\n",
        "validation_dataloader = PromptDataLoader(\n",
        "        dataset=dataset[\"validation\"], \n",
        "        template=mytemplate, \n",
        "        tokenizer=tokenizer, \n",
        "        tokenizer_wrapper_class=WrapperClass, \n",
        "        max_seq_length=128,\n",
        "        decoder_max_length=3,\n",
        "        batch_size=batch_size_ ,\n",
        "        shuffle=False, \n",
        "        teacher_forcing=False, \n",
        "        predict_eos_token=False,\n",
        "        truncate_method=\"tail\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKDCi2JjiHlh"
      },
      "source": [
        "## KnowledgeableVerbalizer & BackTranslation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "I2d2BGj9CUT4"
      },
      "outputs": [],
      "source": [
        "# !pip install BackTranslation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "Zb9iciV4CUT4"
      },
      "outputs": [],
      "source": [
        "# # KnowledgeableVerbalizer\n",
        "# from BackTranslation import BackTranslation\n",
        "# import re \n",
        "# trans = BackTranslation(url=[\n",
        "#       'translate.google.com',\n",
        "#       'translate.google.co.kr',\n",
        "#     ], proxies={'http': '127.0.0.1:1234', 'http://host.name': '127.0.0.1:4012'})\n",
        "\n",
        "# languages = ['af','sq','am','hy','az','eu','be','bn','bs',\n",
        "#              'bg','ca','ceb','ny','zh-cn','zh-tw','co',\n",
        "#              'hr','cs','da','nl','eo','et','tl','fi',\n",
        "#              'fr','fy','gl','ka','de','el','gu','ht','ha',\n",
        "#              'haw','he','hi','hmn','hu','is','ig','id',\n",
        "#              'ga','it','ja','jw','kn','kk','ko','ku','ky','lo',\n",
        "#              'la','lv','lb','mk','mg','ms','ml','mt','mi','mr',\n",
        "#              'mn','my','ne','no','or','ps','fa','pl','pt','pa',\n",
        "#              'ro','ru','sm','gd','sr','st','sn','sd','si','sk','sl',\n",
        "#              'so','es','su','sw','sv','tg','ta','te','th','tr',\n",
        "#              'ur','uk','ug','uz','vi','cy','xh','yi','yo','zu',\n",
        "#              'ar', 'es']\n",
        "\n",
        "# # labels = \"realization\", \"surprise\", \"curiosity\", \"confusion\"\n",
        "# label_words = {}\n",
        "# for i in label_cols:\n",
        "#     print(i + \"\\n\")\n",
        "#     new_words = set()\n",
        "#     for j in languages:\n",
        "#         try:\n",
        "#             print(j)\n",
        "#             result = trans.translate(i, src='en', tmp = j)\n",
        "#             new_word = result.result_text.lower()\n",
        "#             new_word = re.sub(r'[\\W\\s]','',new_word)\n",
        "#             print(new_word)\n",
        "#             new_words.add(new_word)\n",
        "#         except NameError:\n",
        "#             print(j+\"can not as translate target\")    \n",
        "#         except TypeError:\n",
        "#             print(j+\"can not as translate target\")   \n",
        "#     print(new_words)\n",
        "#     label_words[i] = list(new_words)\n",
        "#     print(\"\\n\")\n",
        "# # print(label_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "c_LcS5KWTKFQ"
      },
      "outputs": [],
      "source": [
        "# from nltk.corpus import wordnet\n",
        "\n",
        "# word_lst = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
        "#             'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
        "\n",
        "# synonyms_double_lst = {}\n",
        "# synonyms_lst = []\n",
        "\n",
        "# for i in word_lst:\n",
        "#     for syn in wordnet.synsets(i):\n",
        "#         for lm in syn.lemmas():\n",
        "#             synonyms_lst.append(lm.name())\n",
        "#     synonyms_double_lst[i]=list(set(synonyms_lst))\n",
        "#     synonyms_lst = []\n",
        "\n",
        "# print(synonyms_double_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "QH_8OMTTyxOz"
      },
      "outputs": [],
      "source": [
        "# https://github.com/thunlp/OpenPrompt/blob/main/scripts/TextClassification/agnews/knowledgeable_verbalizer.txt\n",
        "# from openprompt.prompts import KnowledgeableVerbalizer\n",
        "# myverbalizer = KnowledgeableVerbalizer(tokenizer, num_classes=28).from_file(\"scripts/GoEmotions/backTran_verbalizer.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Ii-1rviPit"
      },
      "source": [
        "## ManualVerbalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "mPMnql5qCUT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a49253b-4c30-4c35-c7a7-cacb7b219ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sadness': ['sadness'], 'joy': ['joy'], 'love': ['love'], 'anger': ['anger'], 'fear': ['fear'], 'surprise': ['surprise']}\n"
          ]
        }
      ],
      "source": [
        "# Define the verbalizer\n",
        "# In classification, you need to define your verbalizer, which is a mapping from logits on the vocabulary to the final label probability. Let's have a look at the verbalizer details:\n",
        "\n",
        "from openprompt.prompts import ManualVerbalizer\n",
        "\n",
        "# for example the verbalizer contains multiple label words in each class\n",
        "label_words = {i:[i] for i in labels_}\n",
        "print(label_words)\n",
        "myverbalizer = ManualVerbalizer(tokenizer, \n",
        "                                classes = labels_,\n",
        "                                label_words=label_words)\n",
        "\n",
        "# print(myverbalizer.label_words_ids)\n",
        "# logits = torch.randn(len(labels),len(tokenizer)) # creating a pseudo output from the plm, and \n",
        "# print(myverbalizer.process_logits(logits)) # see what the verbalizer do"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuRDWWyey4Rh"
      },
      "source": [
        "## SoftVerbalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "R2wYs3pHy2g-"
      },
      "outputs": [],
      "source": [
        "# # Soft openprompt\n",
        "# from openprompt.prompts import SoftVerbalizer\n",
        "# myverbalizer = SoftVerbalizer(tokenizer, plm, num_classes=len(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwcYfzDribWZ"
      },
      "source": [
        "# Model & freeze_plm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "GiQwZ-CPCUT4"
      },
      "outputs": [],
      "source": [
        "# Although you can manually combine the plm, template, verbalizer together, we provide a pipeline \n",
        "# model which take the batched data from the PromptDataLoader and produce a class-wise logits\n",
        "\n",
        "from openprompt import PromptForClassification\n",
        "\n",
        "if training_type in ['collapse','new_collapse']:\n",
        "  prompt_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer)\n",
        "\n",
        "  # MLP \n",
        "  for para in prompt_model.plm.fc1.parameters():\n",
        "    para.requires_grad = True\n",
        "\n",
        "  for para in prompt_model.plm.fc2.parameters():\n",
        "    para.requires_grad = True\n",
        "\n",
        "  for para in prompt_model.plm.fc3.parameters():\n",
        "    para.requires_grad = True\n",
        "\n",
        "else:\n",
        "  prompt_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer, freeze_plm=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_cuda:\n",
        "    prompt_model = prompt_model.cuda()"
      ],
      "metadata": {
        "id": "E5rGcN9VaIaX"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "4kXBN1yEyxWg"
      },
      "outputs": [],
      "source": [
        "# print(prompt_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn265jniijYx"
      },
      "source": [
        "### optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "UXwlnViICUT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e26ccfa-64f5-408d-d642-3d436919350a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Now the training is standard\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers.optimization import AdamW \n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "\n",
        "if training_type == 'man':\n",
        "  # man\n",
        "  # it's always good practice to set no decay to biase and LayerNorm parameters\n",
        "  optimizer_grouped_parameters = [\n",
        "      {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "      {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "  ]\n",
        "\n",
        "  optimizer = AdamW(optimizer_grouped_parameters, lr=1e-4)\n",
        "  tot_step  = len(train_dataloader)*5\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, 0, tot_step)\n",
        "else:\n",
        "  # it's always good practice to set no decay to biase and LayerNorm parameters\n",
        "  optimizer_grouped_parameters1 = [\n",
        "      {'params': [p for n, p in prompt_model.plm.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "      {'params': [p for n, p in prompt_model.plm.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "  ]\n",
        "\n",
        "  # Using different optimizer for prompt parameters and model parameters\n",
        "  optimizer_grouped_parameters2 = [\n",
        "      {'params': [p for n,p in prompt_model.template.named_parameters() if \"raw_embedding\" not in n]}\n",
        "  ]\n",
        "\n",
        "  optimizer1 = AdamW(optimizer_grouped_parameters1, lr=model_lr)\n",
        "  optimizer2 = AdamW(optimizer_grouped_parameters2, lr=template_lr)\n",
        "\n",
        "  tot_step  = len(train_dataloader)*5\n",
        "  scheduler1 = get_linear_schedule_with_warmup(optimizer1, 0, tot_step)\n",
        "  scheduler2 = get_linear_schedule_with_warmup(optimizer2, 0, tot_step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y0qTy88isws"
      },
      "source": [
        "### Evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "wF2cQJBDCUT5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "def compute_metrics(labels, preds):\n",
        "    assert len(preds) == len(labels)\n",
        "    results = dict()\n",
        "\n",
        "    results[\"accuracy\"] = accuracy_score(labels, preds)\n",
        "    results[\"macro_precision\"], results[\"macro_recall\"], results[\n",
        "        \"macro_f1\"], _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"macro\")\n",
        "    results[\"micro_precision\"], results[\"micro_recall\"], results[\n",
        "        \"micro_f1\"], _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"micro\")\n",
        "    results[\"weighted_precision\"], results[\"weighted_recall\"], results[\n",
        "        \"weighted_f1\"], _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"weighted\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# labels = [0,1]\n",
        "# preds = [0,0]\n",
        "# print(compute_metrics(labels, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tG8gNG8i2dR"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxq1jNDhi_-V"
      },
      "source": [
        "## Manual Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "55hLjf_X1xhJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "min_f1 = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "JEEqgEkJCUT5"
      },
      "outputs": [],
      "source": [
        "# Manual Prompt\n",
        "if training_type == 'man' and few_shot_train:\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          logits = prompt_model(inputs)\n",
        "          labels = inputs['label']\n",
        "          loss = loss_func(logits, labels)\n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "          optimizer.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  prompt_model.eval()\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              # print(\"Dev acc: \"+str(acc))\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "\n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2JCKV8XjFhA"
      },
      "source": [
        "## Mix/Soft prompt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egqFBEEjCUT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f611d9-1d94-4427-f912-4e3fbb026689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, average loss: 2.335371255874634\n",
            "Dev acc: 0.187\n",
            "Dev f1:0.18101123680040457\n",
            "save model in epoch:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:14<00:57, 14.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, average loss: 1.9589383602142334\n",
            "Dev acc: 0.277\n",
            "Dev f1:0.2543870059961078\n",
            "save model in epoch:1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:28<00:42, 14.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, average loss: 1.7602676749229431\n"
          ]
        }
      ],
      "source": [
        "# Mix prompt Soft\n",
        "if training_type == 'mix' and few_shot_train:\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          \n",
        "          logits, _ = prompt_model(inputs)\n",
        "          \n",
        "          labels = inputs['label']\n",
        "          loss = loss_func(logits, labels)\n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer1.step()\n",
        "          optimizer1.zero_grad()\n",
        "          optimizer2.step()\n",
        "          optimizer2.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              prompt_model.eval()\n",
        "              \n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits, _ = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "\n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfwlMl5ljJP7"
      },
      "source": [
        "# metric_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5F77RoBxEIf"
      },
      "source": [
        "### metric learning level define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzbpYAqUB1ou"
      },
      "outputs": [],
      "source": [
        "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
        "# from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
        "\n",
        "### pytorch-metric-learning stuff ###\n",
        "distance = distances.CosineSimilarity()\n",
        "reducer = reducers.ThresholdReducer(low=0)\n",
        "loss_func_metric = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
        "mining_func = miners.TripletMarginMiner(\n",
        "    margin=0.2, distance=distance, type_of_triplets=\"semihard\"\n",
        ")\n",
        "\n",
        "# 0-positive, 1-negative, 2-ambiguous, 3-neutral\n",
        "# if training_type in ['high_level','collapse','new_collapse'] and dataset_ == 'go_emotions':\n",
        "#   Hierarchical_class_high = {\n",
        "#   0: [\"amusement\", \"excitement\", \"joy\", \"love\", \"desire\", \"optimism\", \"caring\", \"pride\", \"admiration\", \"gratitude\", \"relief\", \"approval\"],\n",
        "#   1: [\"fear\", \"nervousness\", \"remorse\", \"embarrassment\", \"disappointment\", \"sadness\", \"grief\", \"disgust\", \"anger\", \"annoyance\", \"disapproval\"],\n",
        "#   2: [\"realization\", \"surprise\", \"curiosity\", \"confusion\"]\n",
        "#   }\n",
        "\n",
        "# # 0-anger, 1-disgust, 2-fear, 3-joy, 4-sadness, 5-surprise TODO 06/22\n",
        "# elif training_type == 'medium_level' and dataset_ == 'go_emotions':\n",
        "#   Hierarchical_class_mid = {\n",
        "#   0: [\"anger\", \"annoyance\", \"disapproval\"],\n",
        "#   1: [\"disgust\"],\n",
        "#   2: [\"fear\", \"nervousness\"],\n",
        "#   3: [\"joy\", \"amusement\", \"approval\", \"excitement\", \"gratitude\",  \"love\", \"optimism\", \"relief\", \"pride\", \"admiration\", \"desire\", \"caring\"],\n",
        "#   4: [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\",  \"remorse\"],\n",
        "#   5: [\"surprise\", \"realization\", \"confusion\", \"curiosity\"]\n",
        "#   }\n",
        "\n",
        "if dataset_ == 'go_emotions':\n",
        "  Hierarchical_class_high = {\n",
        "  0: [\"amusement\", \"excitement\", \"joy\", \"love\", \"desire\", \"optimism\", \"caring\", \"pride\", \"admiration\", \"gratitude\", \"relief\", \"approval\"],\n",
        "  1: [\"fear\", \"nervousness\", \"remorse\", \"embarrassment\", \"disappointment\", \"sadness\", \"grief\", \"disgust\", \"anger\", \"annoyance\", \"disapproval\"],\n",
        "  2: [\"realization\", \"surprise\", \"curiosity\", \"confusion\"]\n",
        "  }\n",
        "\n",
        "  Hierarchical_class_mid = {\n",
        "  0: [\"anger\", \"annoyance\", \"disapproval\"],\n",
        "  1: [\"disgust\"],\n",
        "  2: [\"fear\", \"nervousness\"],\n",
        "  3: [\"joy\", \"amusement\", \"approval\", \"excitement\", \"gratitude\",  \"love\", \"optimism\", \"relief\", \"pride\", \"admiration\", \"desire\", \"caring\"],\n",
        "  4: [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\",  \"remorse\"],\n",
        "  5: [\"surprise\", \"realization\", \"confusion\", \"curiosity\"]\n",
        "  }\n",
        "\n",
        "elif dataset_ == 'emotion':\n",
        "  Hierarchical_class = {\n",
        "  0: [\"joy\", \"love\"],\n",
        "  1: [\"fear\",  \"sadness\", \"anger\"],\n",
        "  2: [\"surprise\"],\n",
        "  }            \n",
        "\n",
        "def label_change(x):\n",
        "  for key, item in Hierarchical_class.items():\n",
        "    if labels_[x] in item:\n",
        "      return int(key) \n",
        "  return int(len(Hierarchical_class))\n",
        "\n",
        "def label_change_mid(x):\n",
        "  for key, item in Hierarchical_class_mid.items():\n",
        "    if labels_[x] in item:\n",
        "      return int(key) \n",
        "  return int(len(Hierarchical_class))\n",
        "\n",
        "def label_change_high(x):\n",
        "  for key, item in Hierarchical_class_high.items():\n",
        "    if labels_[x] in item:\n",
        "      return int(key) \n",
        "  return int(len(Hierarchical_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mLFuN-XkkPr"
      },
      "source": [
        "### low level Metric Learning（28）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIOQ6DJ5k77c"
      },
      "outputs": [],
      "source": [
        "# low level Metric Learning(28分类)\n",
        "if training_type == 'original' and few_shot_train:\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          logits, _ = prompt_model(inputs)\n",
        "          labels = inputs['label']\n",
        "\n",
        "          indices_tuple1 = mining_func(logits, labels)\n",
        "          loss1 = loss_func_metric(logits, labels, indices_tuple1)\n",
        "\n",
        "          # Hierarchical_labels = inputs['label'].cpu().tolist()\n",
        "          # Hierarchical_labels = list(map(label_change, Hierarchical_labels))\n",
        "          # Hierarchical_labels = torch.Tensor(Hierarchical_labels).to(labels.device)\n",
        "          # indices_tuple2 = mining_func(logits, Hierarchical_labels)\n",
        "          # loss2 = loss_func_metric(logits, Hierarchical_labels, indices_tuple2)\n",
        "\n",
        "          # loss = loss1+loss2\n",
        "          loss = loss1\n",
        "\n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer1.step()\n",
        "          scheduler1.step()\n",
        "          optimizer1.zero_grad()\n",
        "          optimizer2.step()\n",
        "          scheduler2.step()\n",
        "          optimizer2.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              prompt_model.eval()\n",
        "              \n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits, _ = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              # print(\"Dev acc: \"+str(acc))\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "\n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7UatccUxvB9"
      },
      "source": [
        "### Mix/Soft prompt Soft + low level Metric Learning（28）Proxy-NCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oep0WoA9xknK"
      },
      "outputs": [],
      "source": [
        " # low level Metric Learning(28分类)\n",
        "if training_type == 'low_level'and few_shot_train:\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          logits, _ = prompt_model(inputs)\n",
        "          labels = inputs['label']\n",
        "\n",
        "          # 交叉损失\n",
        "          loss1 = loss_func(logits, labels)\n",
        "\n",
        "          # 对比学习损失\n",
        "          indices_tuple1 = mining_func(logits, labels)\n",
        "          loss2 = loss_func_metric(logits, labels, indices_tuple1)\n",
        "\n",
        "          # Hierarchical_labels = inputs['label'].cpu().tolist()\n",
        "          # Hierarchical_labels = list(map(label_change, Hierarchical_labels))\n",
        "          # Hierarchical_labels = torch.Tensor(Hierarchical_labels).to(labels.device)\n",
        "          # indices_tuple2 = mining_func(logits, Hierarchical_labels)\n",
        "          # loss2 = loss_func_metric(logits, Hierarchical_labels, indices_tuple2)\n",
        "\n",
        "          loss = loss1+loss2\n",
        "          # loss = loss1\n",
        "\n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer1.step()\n",
        "          scheduler1.step()\n",
        "          optimizer1.zero_grad()\n",
        "          optimizer2.step()\n",
        "          scheduler2.step()\n",
        "          optimizer2.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              prompt_model.eval()\n",
        "              \n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits, _ = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              # print(\"Dev acc: \"+str(acc))\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "\n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD2KWpCQyDTt"
      },
      "source": [
        "### Mix/Soft prompt Soft + medium level Metric Learning（7）Proxy Anchor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpIOBMcayRuB"
      },
      "outputs": [],
      "source": [
        "# Mix prompt Soft + medium level Metric Learning\n",
        "if training_type == 'medium_level'and few_shot_train:\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          logits, _ = prompt_model(inputs)\n",
        "          labels = inputs['label']\n",
        "          Hierarchical_labels = inputs['label'].cpu().tolist()\n",
        "          Hierarchical_labels = list(map(label_change_mid, Hierarchical_labels))\n",
        "          Hierarchical_labels = torch.Tensor(Hierarchical_labels).to(labels.device)\n",
        "          # 交叉损失\n",
        "          loss1 = loss_func(logits, labels)\n",
        "          # 对比学习\n",
        "          indices_tuple = mining_func(logits, Hierarchical_labels)\n",
        "          loss2 = loss_func_metric(logits, Hierarchical_labels, indices_tuple)\n",
        "          loss = loss1 + loss2 \n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer1.step()\n",
        "          scheduler1.step()\n",
        "          optimizer1.zero_grad()\n",
        "          optimizer2.step()\n",
        "          scheduler2.step()\n",
        "          optimizer2.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              prompt_model.eval()\n",
        "              \n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits, _ = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              # print(\"Dev acc: \"+str(acc))\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "                \n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DJuFHNAt1ne"
      },
      "source": [
        "### Mix/Soft prompt Soft + high level Metric Learning(4) TML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ilMrtwjB1bP"
      },
      "outputs": [],
      "source": [
        "# Mix prompt Soft + Metric Learning\n",
        "if training_type == 'high_level'and few_shot_train:\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          logits, _ = prompt_model(inputs)\n",
        "          labels = inputs['label']\n",
        "          # 交叉损失\n",
        "          loss1 = loss_func(logits, labels)\n",
        "          # 对比学习 TML\n",
        "          Hierarchical_labels = inputs['label'].cpu().tolist()\n",
        "          Hierarchical_labels_mid = list(map(label_change_mid, Hierarchical_labels))\n",
        "          Hierarchical_labels_mid = torch.Tensor(Hierarchical_labels_mid).to(labels.device)\n",
        "          indices_tuple = mining_func(logits, Hierarchical_labels_mid)\n",
        "          loss2 = loss_func_metric(logits, Hierarchical_labels_mid, indices_tuple)\n",
        "\n",
        "          Hierarchical_labels_high = list(map(label_change_high, Hierarchical_labels))\n",
        "          Hierarchical_labels_high = torch.Tensor(Hierarchical_labels_high).to(labels.device)\n",
        "          indices_tuple = mining_func(logits, Hierarchical_labels_high)\n",
        "          loss3 = loss_func_metric(logits, Hierarchical_labels_high, indices_tuple)\n",
        "\n",
        "          loss = loss1 + 1/7*loss2 + 1/4*loss3\n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer1.step()\n",
        "          scheduler1.step()\n",
        "          optimizer1.zero_grad()\n",
        "          optimizer2.step()\n",
        "          scheduler2.step()\n",
        "          optimizer2.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              prompt_model.eval()\n",
        "              \n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits, _ = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              # print(\"Dev acc: \"+str(acc))\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "\n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R7gX67GxhAR"
      },
      "source": [
        "### Mix prompt Soft + Metric Learning bank_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUTW-e2YIlPY"
      },
      "outputs": [],
      "source": [
        "# Mix prompt Soft + Metric Learning bank size\n",
        "if training_type == 'bank'and few_shot_train:\n",
        "  step_index = int(bank_size/batch_size_)\n",
        "  logits_stack = []\n",
        "  labels_stack = []\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          logits = prompt_model(inputs)\n",
        "          labels = inputs['label']\n",
        "          loss1 = loss_func(logits, labels)\n",
        "          \n",
        "          for logit, label in zip(logits.cpu().tolist(), labels.cpu().tolist()):\n",
        "            logits_stack.append(logit)\n",
        "            labels_stack.append(label)\n",
        "\n",
        "          if step % step_index == 1:\n",
        "            # print(\"bank_size\"+str(len(labels_stack)))\n",
        "            # print(len(labels_stack))\n",
        "            # print(labels_stack)\n",
        "            Hierarchical_labels = list(map(label_change,labels_stack))\n",
        "\n",
        "            Hierarchical_labels = torch.Tensor(Hierarchical_labels).to(labels.device)\n",
        "            # print(Hierarchical_labels)\n",
        "            logits_stack = torch.Tensor(logits_stack).to(labels.device)\n",
        "\n",
        "            # contradict loss\n",
        "            indices_tuple = mining_func(logits_stack, Hierarchical_labels)\n",
        "            loss2 = loss_func_metric(logits_stack, Hierarchical_labels, indices_tuple)\n",
        "            # print(loss2)\n",
        "\n",
        "            loss = loss1 + loss2\n",
        "\n",
        "            logits_stack = []\n",
        "            labels_stack = [] \n",
        "          else:\n",
        "            loss = loss1\n",
        "  \n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer1.step()\n",
        "          scheduler1.step()\n",
        "          optimizer1.zero_grad()\n",
        "          optimizer2.step()\n",
        "          scheduler2.step()\n",
        "          optimizer2.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              prompt_model.eval()\n",
        "              \n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              # print(\"Dev acc: \"+str(acc))\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "\n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWr_tuQvyXRu"
      },
      "source": [
        "### Multiple Metric Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhnMl_4SGjs8"
      },
      "outputs": [],
      "source": [
        " # Multiple Metric Learning\n",
        "if training_type == 'multiple'and few_shot_train:\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          logits = prompt_model(inputs)\n",
        "          labels = inputs['label']\n",
        "\n",
        "          indices_tuple1 = mining_func(logits, labels)\n",
        "          loss1 = loss_func_metric(logits, labels, indices_tuple1)\n",
        "\n",
        "          Hierarchical_labels = inputs['label'].cpu().tolist()\n",
        "          Hierarchical_labels = list(map(label_change, Hierarchical_labels))\n",
        "          Hierarchical_labels = torch.Tensor(Hierarchical_labels).to(labels.device)\n",
        "          indices_tuple2 = mining_func(logits, Hierarchical_labels)\n",
        "          loss2 = loss_func_metric(logits, Hierarchical_labels, indices_tuple2)\n",
        "\n",
        "          loss = loss1+loss2\n",
        "\n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer1.step()\n",
        "          scheduler1.step()\n",
        "          optimizer1.zero_grad()\n",
        "          optimizer2.step()\n",
        "          scheduler2.step()\n",
        "          optimizer2.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              prompt_model.eval()\n",
        "              \n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              # print(\"Dev acc: \"+str(acc))\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "\n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7kIlEs0rUGK"
      },
      "source": [
        "# Collapse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp_eYPgEyZ9c"
      },
      "source": [
        "## Mix prompt Soft + Metric Learning bank + collapse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt1_btsMZfpv"
      },
      "outputs": [],
      "source": [
        "# Mix prompt Soft + Metric Learning bank size + collapse TODO\n",
        "from torch import linalg as LA\n",
        "\n",
        "if training_type == 'collapse'and few_shot_train:\n",
        "  step_index = int(bank_size/batch_size_)+1\n",
        "  logits_stack = []\n",
        "  labels_stack = []\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          logits, _ = prompt_model(inputs)\n",
        "\n",
        "          labels = inputs['label']\n",
        "\n",
        "          # prompt loss / class loss\n",
        "          loss1 = loss_func(logits, labels)\n",
        "\n",
        "          # collapse loss\n",
        "          w1 = prompt_model.plm.fc1.weight.cpu()\n",
        "          diff_matrix1 = torch.matmul(w1,w1.transpose(1,0))-torch.eye(w1.shape[0])\n",
        "          loss_w1 = LA.matrix_norm(diff_matrix1)\n",
        "\n",
        "\n",
        "          w2 = prompt_model.plm.fc2.weight.cpu()\n",
        "          diff_matrix2 = w2-torch.eye(w2.shape[0])\n",
        "          loss_w2 = LA.matrix_norm(diff_matrix2)\n",
        "\n",
        "          w3 = prompt_model.plm.fc3.weight.cpu()\n",
        "          diff_matrix3 = torch.matmul(w3,w3.transpose(1,0))-torch.eye(w3.shape[0])\n",
        "          loss_w3 = LA.matrix_norm(diff_matrix3)\n",
        "\n",
        "          loss_collapse =  loss_w1 + loss_w2 + loss_w3\n",
        "          \n",
        "          for logit, label in zip(logits.cpu().tolist(), labels.cpu().tolist()):\n",
        "            logits_stack.append(logit)\n",
        "            labels_stack.append(label)\n",
        "\n",
        "          if step % step_index == 1:\n",
        "            if dataset_ == \"go_emotions\":\n",
        "              Hierarchical_labels = list(map(label_change_high,labels_stack))\n",
        "            elif dataset_ == \"emotion\":\n",
        "              Hierarchical_labels = list(map(label_change,labels_stack))\n",
        "\n",
        "            Hierarchical_labels = torch.Tensor(Hierarchical_labels).to(labels.device)\n",
        "            logits_stack = torch.Tensor(logits_stack).to(labels.device)\n",
        "\n",
        "            # contradict loss\n",
        "            indices_tuple = mining_func(logits_stack, Hierarchical_labels)\n",
        "            loss2 = loss_func_metric(logits_stack, Hierarchical_labels, indices_tuple)\n",
        "\n",
        "            loss = loss1 + loss2 + loss_collapse\n",
        "\n",
        "            logits_stack = []\n",
        "            labels_stack = [] \n",
        "          else:\n",
        "            loss = loss1 + loss_collapse\n",
        "\n",
        "          # print(\"====================\")\n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer1.step()\n",
        "          scheduler1.step()\n",
        "          optimizer1.zero_grad()\n",
        "          optimizer2.step()\n",
        "          scheduler2.step()\n",
        "          optimizer2.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              prompt_model.eval()\n",
        "              \n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits, _ = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "                  \n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              # print(\"Dev acc: \"+str(acc))\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              # f1_score = dev_res[\"weighted_f1\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev weighted_f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "\n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQQhgw8tcOX5"
      },
      "source": [
        "## Mix prompt Soft + SVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQOYtVvicNib"
      },
      "outputs": [],
      "source": [
        "from torch import linalg as LA\n",
        "\n",
        "u_lst = []\n",
        "sigma_lst = []\n",
        "V_lst = []\n",
        "\n",
        "if training_type == 'new_collapse'and few_shot_train:\n",
        "  step_index = int(bank_size/batch_size_)+1\n",
        "  #logits_stack = []\n",
        "  #labels_stack = []\n",
        "  start_time = time.time()\n",
        "  for epoch in tqdm(range(epoch_num)):\n",
        "      tot_loss = 0 \n",
        "      for step, inputs in enumerate(train_dataloader):\n",
        "          prompt_model.train()\n",
        "          if use_cuda:\n",
        "              inputs = inputs.cuda()\n",
        "          logits, _ = prompt_model(inputs)\n",
        "          labels = inputs['label']\n",
        "\n",
        "          # prompt loss / class loss\n",
        "          loss1 = loss_func(logits, labels)\n",
        "          \n",
        "\n",
        "          # print(\"\\n\"+\"loss1\")\n",
        "          # print(loss1)\n",
        "\n",
        "          # collapse loss\n",
        "          w1 = prompt_model.plm.fc1.weight.cpu()\n",
        "          diff_matrix1 = torch.matmul(w1,w1.transpose(1,0))-torch.eye(w1.shape[0])\n",
        "          loss_w1 = LA.matrix_norm(diff_matrix1)\n",
        "\n",
        "          print(\"\\n\"+\"loss_U\")\n",
        "          print(loss_w1)\n",
        "          print(\"\\n\"+\"w_U\")\n",
        "          print(w1)\n",
        "\n",
        "          w2 = prompt_model.plm.fc2.weight.cpu()\n",
        "          # diff_matrix2 = w2-torch.eye(w2.shape[0])\n",
        "          # # print(w2,shape)\n",
        "\n",
        "          # loss_w2 = LA.matrix_norm(diff_matrix2)\n",
        "          loss_w2 = LA.matrix_norm(w2)-1\n",
        "\n",
        "          print(\"\\n\"+\"loss_Sigma\")\n",
        "          print(loss_w2)\n",
        "          print(\"\\n\"+\"w_Sigma\")\n",
        "          print(w2)\n",
        "\n",
        "          w3 = prompt_model.plm.fc3.weight.cpu()\n",
        "          diff_matrix3 = torch.matmul(w3,w3.transpose(1,0))-torch.eye(w3.shape[0])\n",
        "          loss_w3 = LA.matrix_norm(diff_matrix3)\n",
        "\n",
        "          print(\"\\n\"+\"loss_V\")\n",
        "          print(loss_w3)\n",
        "          print(\"\\n\"+\"w_V\")\n",
        "          print(w3)\n",
        "\n",
        "          # TODO \n",
        "          # w0 = prompt_model.plm.bert.cpu() \n",
        "          # diff_matrix0 = w3 - w0\n",
        "          # loss_w4 = LA.matrix_norm(diff_matrix0)\n",
        "\n",
        "          loss_collapse =  loss_w1 + loss_w2 + loss_w3\n",
        "          \n",
        "          # for logit, label in zip(logits.cpu().tolist(), labels.cpu().tolist()):\n",
        "          #   logits_stack.append(logit)\n",
        "          #   labels_stack.append(label)\n",
        "\n",
        "          # if step % step_index == 1:\n",
        "          #   # print(len(labels_stack))\n",
        "          #   # print(labels_stack)\n",
        "          #   Hierarchical_labels = list(map(label_change,labels_stack))\n",
        "\n",
        "          #   Hierarchical_labels = torch.Tensor(Hierarchical_labels).to(labels.device)\n",
        "          #   # print(Hierarchical_labels)\n",
        "          #   logits_stack = torch.Tensor(logits_stack).to(labels.device)\n",
        "\n",
        "          #   # contradict loss\n",
        "          #   indices_tuple = mining_func(logits_stack, Hierarchical_labels)\n",
        "          #   loss2 = loss_func_metric(logits_stack, Hierarchical_labels, indices_tuple)\n",
        "          #   # print(loss2)\n",
        "\n",
        "          #   # print(\"\\n\"+\"loss2\")\n",
        "          #   # print(loss2)\n",
        "          #   loss = loss1 + loss2 + loss_collapse\n",
        "\n",
        "          #   logits_stack = []\n",
        "          #   labels_stack = [] \n",
        "          # else:\n",
        "            # loss = loss1 + loss_collapse\n",
        "\n",
        "          # loss = loss1 + loss_collapse\n",
        "          loss = loss1\n",
        "\n",
        "          # print(\"====================\")\n",
        "          loss.backward()\n",
        "          tot_loss += loss.item()\n",
        "          optimizer1.step()\n",
        "          scheduler1.step()\n",
        "          optimizer1.zero_grad()\n",
        "          optimizer2.step()\n",
        "          scheduler2.step()\n",
        "          optimizer2.zero_grad()\n",
        "          if step %100 == 1:\n",
        "              print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
        "              \n",
        "          if step % 500 == 1:\n",
        "              # evaluation\n",
        "              prompt_model.eval()\n",
        "              \n",
        "              allpreds = []\n",
        "              alllabels = []\n",
        "              for step, inputs in enumerate(validation_dataloader):\n",
        "                  if use_cuda:\n",
        "                      inputs = inputs.cuda()\n",
        "                  logits, _ = prompt_model(inputs)\n",
        "                  labels = inputs['label']\n",
        "                  alllabels.extend(labels.cpu().tolist())\n",
        "                  allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "              # acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "              # print(\"Dev acc: \"+str(acc))\n",
        "              dev_res = compute_metrics(alllabels, allpreds)\n",
        "              acc_score = dev_res[\"accuracy\"]\n",
        "              f1_score = dev_res[\"weighted_f1\"]\n",
        "\n",
        "              print(\"Dev acc: \"+str(acc_score))\n",
        "              print(\"Dev f1:\"+str(f1_score))\n",
        "\n",
        "              if min_f1 < f1_score:\n",
        "                min_f1 = float(f1_score)\n",
        "                print(\"save model in epoch:\"+str(epoch))\n",
        "                torch.save(prompt_model.state_dict(),model_save_pth)\n",
        "                \n",
        "  end_time = time.time()  \n",
        "  complete_time = end_time - start_time\n",
        "  print(\"running time: \"+str(datetime.timedelta(seconds=complete_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzYItYOTylW1"
      },
      "source": [
        "# Test & Zero shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxnEgK6JCUT6"
      },
      "outputs": [],
      "source": [
        "# Test Zero shot\n",
        "test_dataloader = PromptDataLoader(\n",
        "    dataset=dataset[\"test\"], \n",
        "    template=mytemplate, \n",
        "    tokenizer=tokenizer, \n",
        "    tokenizer_wrapper_class=WrapperClass,\n",
        "    max_seq_length=256,  \n",
        "    decoder_max_length=3, \n",
        "    batch_size=batch_size_,\n",
        "    shuffle=False, \n",
        "    teacher_forcing=False, \n",
        "    predict_eos_token=False,\n",
        "    truncate_method=\"tail\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mipl0pGUCUT6"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "if training_type == \"man\" and few_shot_train == False:\n",
        "  test_model = prompt_model\n",
        "else: \n",
        "  test_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer, freeze_plm=True)\n",
        "  test_model.load_state_dict(torch.load(model_save_pth))\n",
        "\n",
        "allpreds = []\n",
        "all_logits = []\n",
        "alllabels = []\n",
        "all_mask = []\n",
        "\n",
        "pbar = tqdm(test_dataloader)\n",
        "for step, inputs in enumerate(pbar):\n",
        "    test_model.eval()\n",
        "    if use_cuda:\n",
        "        inputs = inputs.cuda()\n",
        "\n",
        "    # logits= prompt_model(inputs)\n",
        "    # TokenSim需要用到中间输出 目前只有Bert和No collapse支持\n",
        "    logits, outputs_mask = test_model(inputs)\n",
        "    \n",
        "    labels = inputs['label']\n",
        "\n",
        "    alllabels.extend(labels.cpu().tolist())\n",
        "    allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "    ## store for T-NSE\n",
        "    all_logits.extend(logits.cpu().tolist())\n",
        "\n",
        "    ## store for tokenUmi\n",
        "    all_mask.extend(outputs_mask.cpu().tolist())\n",
        "\n",
        "result = compute_metrics(alllabels, allpreds)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd7ctNEKCUT6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(alllabels, allpreds, target_names=labels_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkbI_gwVu4hX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# 使用sklearn工具中confusion_matrix方法计算混淆矩阵\n",
        "confusion_mat = confusion_matrix(alllabels, allpreds)\n",
        "print(\"confusion_mat.shape : {}\".format(confusion_mat.shape))\n",
        "# print(\"confusion_mat : {}\".format(confusion_mat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8CS_s8mHjkr"
      },
      "outputs": [],
      "source": [
        "# 使用sklearn工具包中的ConfusionMatrixDisplay可视化混淆矩阵，参考plot_confusion_matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_mat, display_labels=labels_)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "disp.plot(\n",
        "    include_values=True,            # 混淆矩阵每个单元格上显示具体数值\n",
        "    cmap=\"YlGnBu\",                 \n",
        "    ax=ax,                        \n",
        "    xticks_rotation=\"vertical\",  \n",
        "    values_format=\"d\"               # 显示的数值格式\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 一维热力图化"
      ],
      "metadata": {
        "id": "U0NsTUVg__xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "7HQh8YpuHvlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "id": "6edfidCr8sFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_logits = torch.mean(logits, dim=0)\n",
        "mean_logits"
      ],
      "metadata": {
        "id": "2ezQC8Qs87MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.heatmap((mean_logits.cpu().detach().numpy()).reshape(1,-1), center=0)"
      ],
      "metadata": {
        "id": "kWrDM1Ph7YNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.heatmap(logits.cpu().detach().numpy(), center=0)"
      ],
      "metadata": {
        "id": "qoXlVEABAS9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.boxplot(data=logits.cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "eM6EMcOqKfR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWf2t-bmx8be"
      },
      "source": [
        "# t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdvJzmVpItSh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import manifold, datasets\n",
        "\n",
        "# X, y = np.array(all_logits), alllabels\n",
        "X, y = np.array(all_mask), alllabels\n",
        "\n",
        "\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_mask[0]"
      ],
      "metadata": {
        "id": "wt5eSqfvMZ94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-bJ95unnZZL"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "hex_list = []\n",
        "for name, hex in matplotlib.colors.cnames.items():\n",
        "    # print(name, hex)\n",
        "    hex_list.append(str(hex))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI_chsjmolI5"
      },
      "outputs": [],
      "source": [
        "len(hex_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv5OL9ZaIvwJ"
      },
      "outputs": [],
      "source": [
        "'''t-SNE'''\n",
        "tsne = manifold.TSNE(n_components=2, init='pca', random_state=42)\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "\n",
        "print(\"Org data dimension is {}. Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
        "\n",
        "'''嵌入空间可视化'''\n",
        "x_min, x_max = X_tsne.min(0), X_tsne.max(0)\n",
        "X_norm = (X_tsne - x_min) / (x_max - x_min)  # 归一化\n",
        "pic_name_tSNE = \"figTSNE/\"+PLM_TYPE+\"_\"+str(training_type)+\"_template_\"+template_type+\"_fewshot_\"+str(num_examples_per_label_)+\"_bankSize_\"+str(bank_size)+\"_dataset_\"+dataset_+\".png\"\n",
        "plt.figure(figsize=(9, 9))\n",
        "for i in range(X_norm.shape[0]):\n",
        "    if y[i] == 27:\n",
        "      continue\n",
        "    if dataset_ == 'go_emotions':\n",
        "      plt.text(X_norm[i, 0], X_norm[i, 1], str(y[i]), color=hex_list[y[i]+1], \n",
        "              fontdict={'weight': 'bold', 'size': 9})\n",
        "    else:\n",
        "      plt.text(X_norm[i, 0], X_norm[i, 1], str(y[i]), color=hex_list[y[i]+10], \n",
        "          fontdict={'weight': 'bold', 'size': 9})\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.savefig(pic_name_tSNE)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuRGrW6ob888"
      },
      "source": [
        "# TokenSim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbnXNCZOjS1R"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "from numpy.linalg import norm\n",
        "from numpy import dot\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF2G3sTyb6gN"
      },
      "outputs": [],
      "source": [
        "def singular_spectrum(W, norm=False): \n",
        "    if norm:\n",
        "        W = W/np.trace(W)\n",
        "    M = np.min(W.shape)\n",
        "    svd = TruncatedSVD(n_components=M-1, n_iter=7, random_state=10)\n",
        "    svd.fit(W) \n",
        "    svals = svd.singular_values_\n",
        "    svecs = svd.components_\n",
        "    return svals, svecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNdD6V-zcVZH"
      },
      "outputs": [],
      "source": [
        "def tokenSimi(tokens_matrix,seqlen=None,nopad=False):\n",
        "    \"\"\"calculate the average cosine similarity,with/without normalization\"\"\"\n",
        "\n",
        "    # simi 计算的是两两之间的关系，而cls_simi计算的是cls位置与其他位置的关系\n",
        "    simi = []\n",
        "    cls_simi = []\n",
        "    if nopad:\n",
        "        l = seqlen\n",
        "    else:\n",
        "        l = tokens_matrix.shape[0]\n",
        "    for i in range(l):\n",
        "        for j in range(l):\n",
        "            if i!=j:\n",
        "                simi.append(dot(tokens_matrix[i],tokens_matrix[j])/(norm(tokens_matrix[i])*norm(tokens_matrix[j])))\n",
        "    for i in range(l):\n",
        "        cls_simi.append(dot(tokens_matrix[0],tokens_matrix[i])/(norm(tokens_matrix[0])*norm(tokens_matrix[i])))\n",
        "    return sum(simi)/len(simi),sum(cls_simi)/len(cls_simi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj4b-EBsZx5R"
      },
      "outputs": [],
      "source": [
        "plt.style.use('default') \n",
        "\n",
        "def draw_hist(hidden_outputs, layer_name):\n",
        "    #all the layers, sample_i = 0,\n",
        "    sample_i = 0\n",
        "    colors = [\"blue\",\"red\",\"cyan\",\"black\",\"green\"]\n",
        "    # plt.subplots(figsize=(8, 4))\n",
        "    sv = []\n",
        "    tokenuni,clsuni = [],[]\n",
        "    for i in range(len(hidden_outputs)):\n",
        "      sv_batch, _ = singular_spectrum(hidden_outputs[i])\n",
        "      # print(sv_batch)\n",
        "      \n",
        "      sv.extend(sv_batch)\n",
        "      tokenUni1,clsUni1 = tokenSimi(hidden_outputs[i])\n",
        "      tokenuni.append(tokenUni1)\n",
        "      clsuni.append(clsUni1)\n",
        "\n",
        "    #keep only one figure handler at once is better\n",
        "    print(\"*****\")\n",
        "    print(training_type)\n",
        "    print(layer_name)\n",
        "    print(np.percentile(sv/max(sv), 10))\n",
        "    print(np.percentile(sv/max(sv), 25))\n",
        "    print(np.percentile(sv/max(sv), 50))\n",
        "    print(\"*****\")\n",
        "\n",
        "    pic_name = \"fig/\"+PLM_TYPE+\"_\"+training_type+\"_template_\"+template_type+\"_fewshot_\"+str(num_examples_per_label_)+\"_bankSize_\"+str(bank_size)+\"_dataset_\"+dataset_+\"_\"+layer_name+\".png\"\n",
        "    print(pic_name)\n",
        "    # pic_name = \"a0Epoch_{}Layer_{}Apply_{}Nonlinear_pdf_average_annotate.png\".format(args.epoch,i_layer,args.apply_exrank1)\n",
        "    fig, axs = plt.subplots(figsize=(8, 5))\n",
        "    w1_stats= stats.describe(sv)\n",
        "    plt.title(\"PDF for {} at Layer {}\".format(training_type,layer_name))\n",
        "    sns.distplot(sv/max(sv), hist=True, kde=True, \n",
        "        bins=50, color = 'darkblue', \n",
        "        hist_kws={'edgecolor':'black'},\n",
        "        kde_kws={'linewidth': 2,\"bw_adjust\":0.1})\n",
        "    \n",
        "    # axs.text(axs.get_xlim()[1]*0.65,axs.get_ylim()[1]*0.6,\"variance:\"+str(\"%.2f\"%w1_stats.variance)+\"\\n\"+\"skewness:\"+str(\"%.2f\"%w1_stats.skewness)+\"\\n\"+\"kurtosis:\"+str(\"%.2f\"%w1_stats.kurtosis)+\"\\n\"+\"tokenuni:\"+str(\"%.2f\"%(sum(tokenuni)/len(tokenuni)))+\"\\n\"+\"clsUni:\"+str(\"%.2f\"%(sum(clsuni)/len(clsuni))),fontsize = 14)\n",
        "    axs.text(axs.get_xlim()[1]*0.65,axs.get_ylim()[1]*0.6,\"skewness:\"+str(\"%.2f\"%w1_stats.skewness)+\"\\n\"+\"\\n\"+\"tokenuni:\"+str(\"%.2f\"%(sum(tokenuni)/len(tokenuni)))+\"\\n\",fontsize = 14)\n",
        "\n",
        "    plt.xlabel(\"singular value\",size=14)\n",
        "    plt.ylabel(\"#singular value\",size=14)\n",
        "    axs.tick_params(axis='x', labelsize=14)\n",
        "    axs.tick_params(axis='y', labelsize=14)\n",
        "\n",
        "    median = np.percentile(sv/max(sv), 50)\n",
        "    axs.vlines(x=median,ymin=0,ymax=0.98*axs.get_ylim()[1],color=\"red\",label=\"median=%.4f\"%median)\n",
        "    axs.legend()\n",
        "    axs.tick_params(axis='x', labelsize=14)\n",
        "\n",
        "    plt.savefig(pic_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoiLmuDdHSkz"
      },
      "outputs": [],
      "source": [
        "#len(np.array(all_mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZGfHPuvHXaT"
      },
      "outputs": [],
      "source": [
        "#np.array(all_mask)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUlmbknOHamW"
      },
      "outputs": [],
      "source": [
        "#len(np.array((all_mask)[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHeRjN3jDqUq"
      },
      "outputs": [],
      "source": [
        "draw_hist([np.array(all_mask)],\"MaskMid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型折线图TODO"
      ],
      "metadata": {
        "id": "JsN66AuL8zea"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJed5Gc48xVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb5B4v2ACUT6"
      },
      "source": [
        "# more detail\n",
        "https://github.com/thunlp/OpenPrompt/blob/main/tutorial/4.1_all_tasks_are_generation.py\n",
        "https://thunlp.github.io/OpenPrompt/modules/root.html?highlight=softtemplate"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "open-prompt-sc.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6004a06cbfb4c548248ac401c5a3bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20db683d57d94a549d5245e2c20ab086",
              "IPY_MODEL_9cb2c5eec2ef4edc9009b3ffd022483d",
              "IPY_MODEL_c179a157bb904d5db8afcc8884e7273e"
            ],
            "layout": "IPY_MODEL_31068be0a724498db2163128dc7c080b"
          }
        },
        "20db683d57d94a549d5245e2c20ab086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_355d83a428b240d6b437c974c9354aef",
            "placeholder": "​",
            "style": "IPY_MODEL_1cdf63658bb74662a5c615af3c43ffc7",
            "value": "100%"
          }
        },
        "9cb2c5eec2ef4edc9009b3ffd022483d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb0d1853ccfe456f98412b8bf99cf035",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_980384950f714e629a89e66c55bb811a",
            "value": 3
          }
        },
        "c179a157bb904d5db8afcc8884e7273e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac99ed05961491eae0cb54c13777ac7",
            "placeholder": "​",
            "style": "IPY_MODEL_f03f80c49853499eb66d96dc2afe8843",
            "value": " 3/3 [00:00&lt;00:00, 88.30it/s]"
          }
        },
        "31068be0a724498db2163128dc7c080b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355d83a428b240d6b437c974c9354aef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cdf63658bb74662a5c615af3c43ffc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb0d1853ccfe456f98412b8bf99cf035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980384950f714e629a89e66c55bb811a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ac99ed05961491eae0cb54c13777ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03f80c49853499eb66d96dc2afe8843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}